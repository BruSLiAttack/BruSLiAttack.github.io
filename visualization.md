## Illustration of Sparse Adversarial Examples

![Figure 1](figures/imagenet-adv ex-visualization.svg#gh-dark-mode-only)

Figure  1: Targeted Attack. Malicious instances is generated by BruSLiAttack with different perturbation budgets against different Deep Learning models on ImageNet. An image with ground-truth label Minibus is misclassified as a Warplane. Interestingly, BruSLiAttack requires 80 perturbed pixels (over 50,176 pixels) to fool ResNet-based models whereas it has to manipulate 220 pixels to mislead Vision Transformer.
